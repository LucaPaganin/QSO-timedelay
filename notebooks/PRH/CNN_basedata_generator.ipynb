{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import importlib\n",
    "import h5py\n",
    "from astropy.stats import sigma_clip\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel\n",
    "from typing import Tuple\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from modules import prh_mc_utils as pmu\n",
    "importlib.reload(pmu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_flux = pmu.mags_to_fluxsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_lag_frac = 0.40\n",
    "files = list(Path('../../data/cnn_base_data/original_data/').glob(\"*.txt\"))\n",
    "outdir = Path(f'../../data/cnn_base_data/qso_base_data')\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    if 'HE0435' in file.name:\n",
    "        imgs = list(itertools.combinations(['A', 'B', 'C', 'D'], 2))\n",
    "    else:\n",
    "        imgs = [('A', 'B')]\n",
    "    \n",
    "    for img1, img2 in imgs:\n",
    "        qso_id = file.name.split('_')[0]\n",
    "        qso_data = pd.read_table(file)\n",
    "        images = [re.search(r'mag_([A-Z])', col).groups()[0] \n",
    "                  for col in qso_data.columns if re.search(r'mag_([A-Z])', col)]\n",
    "        t = qso_data['mhjd'].to_numpy(dtype=np.float64)\n",
    "        mags = {key: qso_data[f'mag_{key}'] for key in images}\n",
    "        magerrs = {key: qso_data[f'magerr_{key}'] for key in images}\n",
    "        \n",
    "        mag1 = mags[img1]\n",
    "        mag2 = mags[img2]\n",
    "        magerr1 = magerrs[img1]\n",
    "        magerr2 = magerrs[img2]\n",
    "\n",
    "        y_input, err_input = comb_flux(mag1, mag2, magerr1, magerr2)\n",
    "\n",
    "\n",
    "        qso_dict = {'t': t, \n",
    "                    f'{img1}': {'y': mag1, 'err_y': magerr1}, \n",
    "                    f'{img2}': {'y': mag2, 'err_y': magerr2},\n",
    "                    f'{img1}+{img2}': {'y': y_input, 'err_y': err_input}\n",
    "                   }\n",
    "        \n",
    "        kernel = ConstantKernel(2, (1e-3, 1e2)) * Matern(length_scale=200.0, length_scale_bounds=(1, 300), nu=1.5)\n",
    "\n",
    "        gp = GaussianProcessRegressor(kernel=kernel, alpha=err_input**2, n_restarts_optimizer=10, \n",
    "                                      optimizer='fmin_l_bfgs_b', normalize_y=True)\n",
    "\n",
    "        gp.fit(np.expand_dims(t,1), y_input)\n",
    "\n",
    "        N = 2000\n",
    "        dt_extension = 0\n",
    "        support, step = np.linspace(t[0] - dt_extension, t[-1] + dt_extension, N, retstep=True)\n",
    "\n",
    "        y_pred, cov_pred = gp.predict(np.expand_dims(support, 1), return_cov=True)\n",
    "        sigma_pred = np.sqrt(np.diag(cov_pred))\n",
    "        L = np.linalg.cholesky(cov_pred)\n",
    "        win = int(dt_extension/step)\n",
    "\n",
    "        gp_dict = {'t': support, 'y_pred': y_pred, 'sigma_pred': sigma_pred, 'cov_pred': cov_pred}\n",
    "        \n",
    "        tau, v = pmu.estimate_structure_func_from_data(support, y_pred, sigma_pred, n_bins=50)\n",
    "        tau = tau[v>=0]\n",
    "        v = v[v>=0]\n",
    "\n",
    "        max_lag = cut_lag_frac*tau[-1]\n",
    "\n",
    "        tau_cut = tau[tau <= max_lag]\n",
    "        v_cut   = v[tau <= max_lag]\n",
    "\n",
    "        p = stats.linregress(np.log10(tau_cut), np.log10(v_cut))\n",
    "\n",
    "        sf_dict = {'tau_cut': tau_cut, \n",
    "                   'v_cut': v_cut,\n",
    "                   'slope': p[0],\n",
    "                   'intercept': p[1],\n",
    "                   'tau_not_cut': tau,\n",
    "                   'v_not_cut': v}\n",
    "        \n",
    "        pmu.create_qso_base_file(qso_dict=qso_dict, \n",
    "                                 gp_dict=gp_dict, \n",
    "                                 sf_dict=sf_dict, \n",
    "                                 outfile=Path(outdir/f'{qso_id}_{img1}{img2}_cut_{cut_lag_frac}.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

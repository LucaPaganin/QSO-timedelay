{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "import sys\n",
    "import mpld3\n",
    "\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from modules import prh\n",
    "from modules import regression as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load QSO data and instantiate Generator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../data/cosmograil_data/HE0435_Bonvin2016.rdb_.txt')\n",
    "\n",
    "prh_gen = prh.LightCurvePRHGenerator()\n",
    "prh_gen.loadQSODataFromFile(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate structure function from data\n",
    "\n",
    "By default it is a power law fit; let's use it like it is for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prh_gen.evaluateStructureFunction()\n",
    "prh_gen.fitStructureFunctionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a dataset for a given delay\n",
    "\n",
    "Let's generate a dataset of 100 MC realizations of light curves pairs, all with a relative time delay of 50 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_delay = 50\n",
    "N_MC_samples = 100\n",
    "\n",
    "outfile_name = f'{prh_gen.qso_id}_delay_{true_delay}d_NMC_{N_MC_samples}.h5'\n",
    "outfile = Path('../aux') / outfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prh_gen.generatePRHDatasetForDelay(true_delay=true_delay, N_MC_samples=N_MC_samples, outfile=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Instantiate dataset class and load from file the dataset you have just generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prh.LightCurvePRHDataset(input_file=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all get the true QSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qso_data = dataset.getOriginalQSOData()\n",
    "\n",
    "t = qso_data['time_domain'][()]\n",
    "qso_lc_vals = qso_data['qso_light_curve_values'][()]\n",
    "qso_lc_errs = qso_data['qso_light_curve_errors'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a given realization from the dataset, using an index from 1 to N_MC_samples, along with its errors. At the moment the errors on the MC realizations are the same of the original data errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dataset.getMCRealization(5)\n",
    "\n",
    "yA = r['yA'][()]\n",
    "yB = r['yB'][()]\n",
    "errA = r['errA'][()]\n",
    "errB = r['errB'][()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(t, qso_lc_vals - qso_lc_vals.mean(), label='true data')\n",
    "plt.scatter(t, yA - yA.mean(), label='MC curve A')\n",
    "plt.scatter(t, yB - yB.mean(), label='MC curve B')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some insights in the procedure; first of all fit two gaussian processes to the MC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ConstantKernel(2, (1e-3, 1e2)) * Matern(length_scale=200.0, length_scale_bounds=(1, 300), nu=1.5)\n",
    "\n",
    "gpA = rg.fit_GP_to_lightcurve(t, yA, errA, kernel)\n",
    "gpB = rg.fit_GP_to_lightcurve(t, yB, errB, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new time support vector choosing a step, and predict using gaussian on this new support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_step = 10.0\n",
    "support = np.arange(t[0] - 50, t[-1] + 50, gp_step)\n",
    "\n",
    "ypredA, sigmaA = gpA.predict(np.expand_dims(support, 1), return_std=True)\n",
    "ypredB, sigmaB = gpB.predict(np.expand_dims(support, 1), return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results at a given confidence level, along with the MC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL = 0.95\n",
    "\n",
    "plt.scatter(t, yA, label='MC curve A', color='b')\n",
    "plt.scatter(t, yB, label='MC curve B', color='g')\n",
    "\n",
    "plt.fill_between(support, ypredA - special.erfinv(CL)*sigmaA, ypredA + special.erfinv(CL)*sigmaA,\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval A')\n",
    "plt.fill_between(support, ypredB - special.erfinv(CL)*sigmaB, ypredB + special.erfinv(CL)*sigmaB,\n",
    "         alpha=.5, fc='g', ec='None', label='95% confidence interval B')\n",
    "plt.legend(fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_estimate = rg.time_delay_grid_search(ypredA, ypredB,\n",
    "                                        sigmaA, sigmaB,\n",
    "                                        gp_step,\n",
    "                                        dt_min=0, dt_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To directly get an estimate of the time delay between the MC curves, without doing the intermediate steps (they are all in the following function) do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_estimate = rg.estimate_delay(t, yA, yB, errA, errB)\n",
    "\n",
    "print(f'Estimated delay: {dt_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
